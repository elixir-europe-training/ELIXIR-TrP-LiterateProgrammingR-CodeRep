---
title: "Example analysis of Wisconsin breast cancer data"
author: "Clement Lee (Literate Programming Team)"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    number_sections: true
    toc: false
  html_document:
    number_sections: true
classoption: a4paper
---

# Introduction & exploratory data analysis
This is an example analysis of the Wisconsin breast cancer data (available [here](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data)) done in R.

## Preamble
Before reading in the data, we load the packages required. We also set the theme of the plots using `theme_set()` in package `ggplot2`.

```{r prelim, message = FALSE}
library(tibble)
library(dplyr)
library(ggplot2)
library(caret)
library(ROCR)
library(pROC)
source("plots.R")
source("models.R")
theme_set(theme_bw(12))
```

## Read data
Now we read the data, available as a local csv file in the relative path (`breast-cancer-wisconsin/`) below. We use various functions to have a glimpse of its structure and dimensions. We also change the `diagnosis` variable to a factor.

```{r read}
cancer_data <- as_tibble(read.csv("data/breast-cancer-wisconsin.csv"))
head(cancer_data)
cancer_data$diagnosis <- as.factor(cancer_data$diagnosis)
colnames(cancer_data)
dim(cancer_data)
```

Echoing the dimensions printed in the output above, this data frame has `r nrow(cancer_data)` rows and `r ncol(cancer_data)` columns. Except for the first two columns, the remaining columns are features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.

We use the following code to remove columns with missing values (`NA`), and have a glimpse of the remaining columns again.

```{r remove_na}
cancer_data <- cancer_data |> select(where(~ all(!is.na(.x))))
head(cancer_data)
```

## Basic summaries
Using the column `diagnosis` in the data, we count that there are `r sum(cancer_data$diagnosis == "M")` Malignant tumours and `r sum(cancer_data$diagnosis == "B")` Benign tumours. We can also plot these counts:
```{r plot-counts, fig.cap = "Counts of data according to tumour status", fig.align = "center", out.width = "70%", fig.asp = 0.65, message = FALSE}
plot_count(cancer_data)
```





# Visualisations and tests of three features
To understand the data better, it is useful to look at, for each tumour status, the distribution of individual features / variables. As an illustration, we shall look at three of them.

## Histogram & density
We first visualise such distributions using histograms and density plots in Figure \@ref(fig:plot-hist). As the same kind of plot is required, a function is written for convenience.

```{r plot-hist, fig.show = "hold", fig.cap = "Histogram and density of three features according to tumour status", fig.align = "center", out.width = "70%", fig.asp = 0.65, message = FALSE}
plot_hist_den(
  cancer_data, var = area_worst, label = "Area worst", filename = "hist_area.png"
)
plot_hist_den(
  cancer_data, var = fractal_dimension_mean, label = "Fractal dimension mean",
  filename = "hist_frac.png"
)
plot_hist_den(
  cancer_data, var = radius_se, label = "Radius se", filename = "hist_radius.png"
)
```

It can be seen that the distribution of each of these three features is different for the tumour status. Therefore, they might be useful or, more precisely, significant when predicting whether the cancer is benign or malignant.

## Boxplots
Another way of visualising the distribution of the three variables above, grouped by the tumuor status, is the box plots in Figure \@ref(fig:plot-boxplot):

```{r plot-boxplot, fig.cap = "Boxplot of three features according to tumour status", fig.show = "hold", fig.pos = "!h", fig.align = "center", out.width = "70%", fig.asp = 0.65, message = FALSE}
plot_boxplot(
  cancer_data, var = area_worst, label = "Area worst", filename = "boxplot_area.png"
)
plot_boxplot(
  cancer_data, var = fractal_dimension_mean, label = "Fractal dimension mean",
  filename = "boxplot_frac.png"
)
plot_boxplot(
  cancer_data, var = radius_se, label = "Radius se", filename = "boxplot_radius.png"
)
```

## Smoothed plots
We suspect each of these three variables has an influence on the tumuor status, so we plot `diagnosis` against each of them in Figure \@ref(fig:plot-smoothed), with the fitted line according to logistic regression. Note the transformation of `diagnosis` to a probability, with `B` and `M` mapped to 0 and 1, respectively.

```{r plot-smoothed, warning = FALSE, message = FALSE, fig.cap = "Tumour status against each feature with fitted logistic regression line", fig.show = "hold", fig.pos = "!h", fig.asp = 0.5, fig.align = "center", out.width = "70%", fig.asp = 0.65, message = FALSE}
plot_logistic_smoothed(
  cancer_data, var = area_worst, filename = "smoothed_area.png"
)
plot_logistic_smoothed(
  cancer_data, var = fractal_dimension_mean, filename = "smoothed_frac.png"
)
plot_logistic_smoothed(
  cancer_data, var = radius_se, filename = "smoothed_radius.png"
)
```
## Statistical tests
We can perform two-sample *t*-test to find out if there is a significant difference in the distribution of a feature according to the tumour status.
```{r ttest, results = "hold"}
area_worst_B <- cancer_data$area_worst[cancer_data$diagnosis == "B"]
area_worst_M <- cancer_data$area_worst[cancer_data$diagnosis == "M"]
ttest0 <- t.test(area_worst_B, area_worst_M, var.equal = TRUE)
options(scipen = 3, digits = 3)
```

The $t$-statistic is `r ttest0$statistic` and the $p$-value is `r ttest0$p.value`. We can write a function to carry out the test more systematically:
```{r ttest_functional}
ttest1 <- ttest_var(cancer_data, var = area_worst)
ttest2 <- ttest_var(cancer_data, var = fractal_dimension_mean)
ttest3 <- ttest_var(cancer_data, var = radius_se)
```

The results are in the following table:

| Variable | $t$-statistic | $p$-value |
|----------|---------------|-----------|
|Area worst|`r ttest1$statistic`| `r ttest1$p.value`|
|Fractal dimension mean|`r ttest2$statistic`| `r ttest2$p.value`|
|Radius se|`r ttest3$statistic`| `r ttest3$p.value`|





# Multicollinearity & correlation heatmaps
When fitting a statistical / machine learning model, pairs of features that have very high (positive or negative) correlation will likely bring about multicollinearity issues. Therefore we investigate the correlations of these features after dropping identifier and tumour status variables.

```{r drop, results = "hold"}
input_data <- cancer_data |> select(-id, -diagnosis)
```

**Heatmaps** provide an informative way to depict two-dimensional data of the kind we have before us. Therefore, using the resultant data frame (of `r nrow(input_data)` rows and `r ncol(input_data)` columns), we plot a heatmap in which the colour of each raster is determined by the Pearson correlation of each corresponding pair of features.

```{r plot-corr, fig.cap = "Correlation matrix heatmap", out.width = "80%", fig.align = "center", fig.asp = 0.65, message = FALSE}
plot_heatmap(input_data, filename = "heatmap.png")
```

We proceed to remove those pairs with high correlations, and print the names of the remaining columns.

```{r drop_corr}
correlation_data <- remove_cols_high_cor(input_data)
names(correlation_data)
```





# Machine learning
Lastly, we apply some machine learning methods, specifically the logistic regression model. Standard cross validation steps with training and testing data are carried out. The following R code chunk is equivalent to using `train_test_split()` in `sklearn.model_selection` in Python.

```{r cross_validation, warning = FALSE}
list_model <- create_model(cancer_data)
pred_y <- list_model$pred
cancer_test <- list_model$test
```

## Confusion matrix
The confusion matrix can be calculated using a function in the package `caret`.

```{r confusion_matrix}
cm <- confusionMatrix(pred_y, cancer_test$diagnosis, positive = 'M')
cm
TN <- cm$table[1,1]
TP <- cm$table[2,2]
FN <- cm$table[2,1]
FP <- cm$table[1,2]
```

Using the confusion matrix and quantities defined above, the accuracy of the method on the test data is `r (TP + TN) / (TP + TN + FN + FP)`.

## Classification report
Classification report is used in machine learning to compute accuracy of a classification model from the values of the confusion matrix. In the classification report, precision is a measure of positive predictions. A few metrics are presented here:

```{r classification_report}
sensitivity(pred_y, cancer_test$diagnosis, positive = "M")
specificity(pred_y, cancer_test$diagnosis, positive = "M")
posPredValue(pred_y, cancer_test$diagnosis, positive = "M")
negPredValue(pred_y, cancer_test$diagnosis, positive = "M")
precision(pred_y, cancer_test$diagnosis, positive = "M")
recall(pred_y, cancer_test$diagnosis, positive = "M")
```

## ROC curve
Another measure for the usefulness of a machine learning model is the ROC curve. To obtain the ROC curve, we first calculate AUC score for the logistic regression model:

```{r auc}
pred_y_num <- as.numeric(pred_y)
test_diagnosis_num <- as.numeric(cancer_test$diagnosis)
auc_cancer <- auc(pred_y_num, test_diagnosis_num)
```

Then we calculate and plot the ROC curve in Figure \@ref(fig:roc):

```{r roc, fig.cap = "ROC curve for the logistic regression model. Source: Wisconsin Breast Cancer Dataset.", fig.align = "center", out.width = "70%", fig.asp = 0.65, message = FALSE}
plot_roc(pred_y, cancer_test$diagnosis, filename = "roc.png")
```




# For reproducibility (via containers?)
For reproducibility purposes, the packages used are shown below:

```{r session_info}
sessionInfo()
```
